# ðŸ“Š Challenge TelecomX - Parte 02

## ðŸ“Œ DescriÃ§Ã£o
Este projeto tem como objetivo analisar dados de clientes de uma empresa de telecomunicaÃ§Ãµes e construir modelos de Machine Learning para prever **churn** (cancelamento de clientes).  
O desafio consiste em comparar diferentes algoritmos, ajustar hiperparÃ¢metros e avaliar o desempenho dos modelos, buscando identificar o que melhor equilibra **precisÃ£o** e **recall**.

---

## ðŸŽ¯ Objetivos
- Realizar anÃ¡lise exploratÃ³ria dos dados (EDA).  
- PrÃ©-processar as variÃ¡veis (normalizaÃ§Ã£o, one-hot encoding etc.).  
- Treinar e avaliar diferentes modelos de classificaÃ§Ã£o:  
  - Dummy Classifier  
  - Decision Tree Classifier  
  - KNN (inicial e ajustado)  
- Comparar mÃ©tricas: **AcurÃ¡cia, PrecisÃ£o, Recall, F1-score e Matriz de ConfusÃ£o**.  
- Identificar sinais de **overfitting** e **underfitting**.  
- Sugerir prÃ³ximos passos para melhoria do modelo.  

---

## âš™ï¸ InstalaÃ§Ã£o e DependÃªncias
Antes de executar o projeto, certifique-se de ter o Python 3.x instalado e crie um ambiente virtual.  
As principais bibliotecas utilizadas foram:


```bash
pip install pandas numpy scikit-learn matplotlib seaborn jupyter


## Como Executar o Projeto

>1.Clone este repositÃ³rio ou baixe os arquivos.

>2.Instale as dependÃªncias listadas acima.

>3.Abra o Notebook no Google Colab:
jupyter notebook Challenge_TelecomX_Parte02.ipynb

>4.Execute as cÃ©lulas em ordem para reproduzir as anÃ¡lises e resultados.


Principais Resultados

--Dummy Classifier: AcurÃ¡cia de ~0.73, nÃ£o conseguiu identificar clientes churn.

--Decision Tree (max_depth=3): Melhor precisÃ£o (0.69) e boa generalizaÃ§Ã£o, sem sinais de overfitting.

--KNN Inicial: Recall maior que a Ã¡rvore, mas apresentou overfitting.

--KNN Ajustado (n=11, distÃ¢ncia Manhattan): Melhor F1-score (0.56) e maior recall, equilibrando precisÃ£o e recall.


ConclusÃ£o:

O Decision Tree Ã© mais indicado se a prioridade for precisÃ£o.

O KNN Ajustado Ã© mais indicado se a prioridade for recall (captar mais clientes em risco de churn).


PrÃ³ximos Passos

>>Explorar Feature Engineering para criar novas variÃ¡veis relevantes.

>>Tratar o desbalanceamento de classes (oversampling/undersampling).

>>Testar outros algoritmos: Logistic Regression, Random Forest, Gradient Boosting.

>>Aplicar validaÃ§Ã£o cruzada para obter mÃ©tricas mais robustas.

>>Analisar casos de erros do modelo (falsos positivos/negativos).


Autor
jaqueline-quaresma


